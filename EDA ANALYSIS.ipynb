{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jImcGzv2GEOu"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import missingno as msno\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet,Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9YmuV7XGMjJ"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/Crop_production.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57rBrmUuIE7_"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MV6HcPgId7w"
      },
      "outputs": [],
      "source": [
        "df.isna()/len(df)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MZFPfgpR08A"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcP7COxOR1ns"
      },
      "outputs": [],
      "source": [
        "df.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0uBQeIAAj2o"
      },
      "outputs": [],
      "source": [
        "print(df[df['Crop'] == 'Cotton'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiPiYvM7R5NB"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y4FIlBLyd54"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-SivTNnBUxA"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZF34XcV5tad"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Create an instance of the OrdinalEncoder\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "# Fit the encoder to the 'Crop' column and transform it\n",
        "df['Crop_Type_encoded'] = encoder.fit_transform(df[['Crop_Type']])\n",
        "df['State_Name_encoded'] = encoder.fit_transform(df[['State_Name']])\n",
        "\n",
        "# Display the DataFrame with the encoded column\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QXYrCO9QcsY"
      },
      "outputs": [],
      "source": [
        "df1 = df.drop('Unnamed: 0', inplace=True)\n",
        "df1 = df.drop('State_Name', inplace=True)\n",
        "df1 = df.drop('Crop_Type', inplace=True)\n",
        "df1 = df.drop('Crop', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3z-yAyG3762"
      },
      "outputs": [],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usfNlyH77G7O"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "df.hist()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pBUHrpb7dgt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "df.boxplot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfV6pDCB8ajZ"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column=['temperature'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB4ISz8p6t5G"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df['Production_in_tons'], df['Area_in_hectares'])\n",
        "plt.xlabel('Production_in_tons')\n",
        "plt.ylabel('Area_in_hectares')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klRXj7CEDOBL"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI6ni69-puJt"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti1tohAbp4CY"
      },
      "outputs": [],
      "source": [
        "df.corr()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbhiNTLgtUR-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df.corr()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsuPWm5xt1mI"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.heatmap(df.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GMTigeL1t-n6"
      },
      "outputs": [],
      "source": [
        "# heatmap\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"viridis\", linewidths=.5)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSOkTb2n0kwp"
      },
      "outputs": [],
      "source": [
        "mask = (df.corr() > 0.7)\n",
        "\n",
        "\n",
        "filtered_correlation_matrix = df.corr().where(mask)\n",
        "\n",
        "\n",
        "sns.heatmap(filtered_correlation_matrix, annot=True, cmap=\"plasma\", linewidths=.5)\n",
        "plt.title(\"Correlation Matrix (>|0.7|)\")\n",
        "plt.show()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GV7qQhKw4Mi3"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nPe5F4tr74IY"
      },
      "outputs": [],
      "source": [
        "df.Crop.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK_AWIlumPjd"
      },
      "outputs": [],
      "source": [
        "columns_to_convert = ['N', 'P', 'K']\n",
        "for col in columns_to_convert:\n",
        "    if col in df.columns and df[col].dtype == np.int64:\n",
        "        df[col] = df[col].astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-QFNx3mQXy"
      },
      "outputs": [],
      "source": [
        "columns_to_convert = ['pH', 'rainfall', 'temperature', 'Production_in_tons', 'Yield_ton_per_hec','Area_in_hectares']\n",
        "for col in columns_to_convert:\n",
        "    if col in df.columns and df[col].dtype == np.float64:\n",
        "        df[col] = df[col].astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRGBqDwamWD5"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELc8ch-vR_Za"
      },
      "outputs": [],
      "source": [
        "columns_to_convert = ['Crop_encoded','Crop_Type_encoded','State_Name_encoded']\n",
        "for col in columns_to_convert:\n",
        "    if col in df.columns and df[col].dtype == np.float64:\n",
        "        df[col] = df[col].astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ_3KloX2YN1"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Yield_ton_per_hec', axis=1)  # Features\n",
        "y = df['Yield_ton_per_hec']  # Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6F6dVgs2jUV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYp8D2maJfZw"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_train = y_train.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Option 1: Remove rows with NaN values\n",
        "# X_train = X_train[y_train.notna()]\n",
        "# y_train = y_train[y_train.notna()]\n",
        "\n",
        "# Option 2: Impute NaN values with the mean or median\n",
        "y_train = y_train.fillna(y_train.mean())  # Or use y_train.median()\n",
        "\n",
        "models = [RandomForestRegressor(), LinearRegression(), ElasticNet(), KNeighborsRegressor(), xgb.XGBRegressor(), Ridge()]\n",
        "scores = dict()\n",
        "\n",
        "for model in models:  # Changed 'models' to 'model' in the loop\n",
        "    # Replace infinite or overly large values in X_train with NaN\n",
        "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
        "    # Impute NaN values with the mean\n",
        "    X_train = X_train.fillna(X_train.mean())\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(y_pred)\n",
        "\n",
        "    print(f'model: {str(model)}')\n",
        "    print(f'RMSE: {mean_squared_error(y_test, y_pred)}')\n",
        "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "    print('-' * 30, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SWf5p81TS3c"
      },
      "outputs": [],
      "source": [
        "# ... your existing code ...\n",
        "\n",
        "model = xgb.XGBRegressor()  # Initialize the XGBoost model\n",
        "model.fit(X_train, y_train)  # Fit the model with your training data\n",
        "\n",
        "# Predict on the test data to avoid implicit display of the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ... (rest of your code where you actually use y_pred)..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogLOba6iT2yw"
      },
      "outputs": [],
      "source": [
        "# ... your existing code ...\n",
        "\n",
        "# Import XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBRegressor()  # Initialize the XGBoost model\n",
        "model.fit(X_train, y_train)  # Fit the model with your training data\n",
        "\n",
        "# Predict on the test data to avoid implicit display of the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ... (rest of your code where you actually use y_pred)..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TALLDJDGTg0Y"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn==1.3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdIKQExnoNNk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM_RUgdSqVDO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define input widgets for each feature\n",
        "N_input = widgets.IntText(description=\"N:\")\n",
        "P_input = widgets.IntText(description=\"P:\")\n",
        "K_input = widgets.IntText(description=\"K:\")\n",
        "temperature_input = widgets.FloatText(description=\"Temperature:\")\n",
        "pH_input = widgets.FloatText(description=\"pH:\")\n",
        "area_input = widgets.IntText(description=\"Area (hectares):\")\n",
        "rainfall_input = widgets.FloatText(description=\"Rainfall:\")\n",
        "# Assuming 'Production_in_tons' is a necessary feature, include it as well:\n",
        "production_input = widgets.FloatText(description=\"Production (tons):\") # Placeholder for now, consider its actual purpose\n",
        "\n",
        "# Function to handle prediction when button is clicked\n",
        "def predict_on_input(b):\n",
        "    input_data = pd.DataFrame({\n",
        "        'N': [N_input.value],\n",
        "        'P': [P_input.value],\n",
        "        'K': [K_input.value],\n",
        "        'temperature': [temperature_input.value],\n",
        "        'pH': [pH_input.value],\n",
        "        'Area_in_hectares': [area_input.value],\n",
        "        'rainfall': [rainfall_input.value],\n",
        "        'Production_in_tons': [production_input.value] # Placeholder for now, consider its actual purpose\n",
        "    })\n",
        "\n",
        "    # Ensure the order of columns matches the training data\n",
        "    input_data = input_data[['N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Area_in_hectares', 'Production_in_tons']]\n",
        "\n",
        "    predictions = model.predict(input_data)\n",
        "    print(\"Predicted Value:\", predictions[0])\n",
        "\n",
        "\n",
        "# Create a button to trigger prediction\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "predict_button.on_click(predict_on_input)\n",
        "\n",
        "# Display the input widgets and button\n",
        "display(N_input, P_input, K_input, temperature_input, pH_input, area_input, rainfall_input, production_input, predict_button)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rle31P2J789E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEg0h45VBMfE"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4G2kLJd_HyY"
      },
      "outputs": [],
      "source": [
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision: {precision}\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}