{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3zh37SL_MYyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import missingno as msno\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet,Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fLnw4xzV1ocw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08emcTW_1R_Y"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/Crop_production.csv')"
      ]
    },
    {
      "source": [
        "df1 = df.copy()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JU7dViYw13X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(\n",
        ")"
      ],
      "metadata": {
        "id": "i2xuV8C416bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop('Unnamed: 0',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "dNCRVw_x19ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop('State_Name',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "DiMi1vjk2Hwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop('Crop_Type',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "M08e5dwP2SN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop('Crop',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "vKQsm4SJ2WsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "state_encoder = LabelEncoder()\n",
        "crop_type_encoder = LabelEncoder()\n",
        "crop_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoders on the training data to avoid data leakage\n",
        "state_encoder.fit(df['State_Name'])\n",
        "crop_type_encoder.fit(df['Crop_Type'])\n",
        "crop_encoder.fit(df['Crop'])\n",
        "\n",
        "# Transform the categorical features in the entire DataFrame\n",
        "df1['State_Name_Encoded'] = state_encoder.transform(df['State_Name'])\n",
        "df1['Crop_Type_Encoded'] = crop_type_encoder.transform(df['Crop_Type'])\n",
        "df1['Crop_Encoded'] = crop_encoder.transform(df['Crop'])\n",
        "\n",
        "# Now, 'df' contains the encoded features and you can use it for training/prediction"
      ],
      "metadata": {
        "id": "mmwI-e5JPMpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "1G-u4uMt2d0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.drop('Yield_ton_per_hec', axis=1)  # Features\n",
        "y = df1['Yield_ton_per_hec']  # Target variable"
      ],
      "metadata": {
        "id": "wiioyoq62lKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "zm3dckzH207J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = y_train.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Option 1: Remove rows with NaN values\n",
        "# X_train = X_train[y_train.notna()]\n",
        "# y_train = y_train[y_train.notna()]\n",
        "\n",
        "# Option 2: Impute NaN values with the mean or median\n",
        "y_train = y_train.fillna(y_train.mean())  # Or use y_train.median()\n",
        "\n",
        "models = [RandomForestRegressor(), LinearRegression(), ElasticNet(), KNeighborsRegressor(), xgb.XGBRegressor(), Ridge()]\n",
        "scores = dict()\n",
        "\n",
        "for model in models:  # Changed 'models' to 'model' in the loop\n",
        "    # Replace infinite or overly large values in X_train with NaN\n",
        "    X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
        "    # Impute NaN values with the mean\n",
        "    X_train = X_train.fillna(X_train.mean())\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(y_pred)\n",
        "\n",
        "    print(f'model: {str(model)}')\n",
        "    print(f'RMSE: {mean_squared_error(y_test, y_pred)}')\n",
        "    print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
        "    print('-' * 30, '\\n')"
      ],
      "metadata": {
        "id": "61Ho43fQ26yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model = xgb.XGBRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "T_aig_n13E8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "KeITGaYe7JOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Define input widgets for each feature\n",
        "N_input = widgets.IntText(description=\"N:\")\n",
        "P_input = widgets.IntText(description=\"P:\")\n",
        "K_input = widgets.IntText(description=\"K:\")\n",
        "temperature_input = widgets.FloatText(description=\"Temperature:\")\n",
        "pH_input = widgets.FloatText(description=\"pH:\")\n",
        "area_input = widgets.IntText(description=\"Area (hectares):\")\n",
        "rainfall_input = widgets.FloatText(description=\"Rainfall:\")\n",
        "# Assuming 'Production_in_tons' is a necessary feature, include it as well:\n",
        "production_input = widgets.FloatText(description=\"Production (tons):\") # Placeholder for now, consider its actual purpose\n",
        "\n",
        "# Dropdown widgets for categorical features\n",
        "state_input = widgets.Dropdown(\n",
        "    options=df['State_Name'].unique().tolist(),\n",
        "    description=\"State:\"\n",
        ")\n",
        "crop_type_input = widgets.Dropdown(\n",
        "    options=df['Crop_Type'].unique().tolist(),\n",
        "    description=\"Crop Type:\"\n",
        ")\n",
        "crop_input = widgets.Dropdown(\n",
        "    options=df['Crop'].unique().tolist(),\n",
        "    description=\"Crop:\"\n",
        ")\n",
        "\n",
        "# Function to handle prediction when button is clicked\n",
        "def predict_on_input(b):\n",
        "    input_data = pd.DataFrame({\n",
        "        'N': [N_input.value],\n",
        "        'P': [P_input.value],\n",
        "        'K': [K_input.value],\n",
        "        'temperature': [temperature_input.value],\n",
        "        'pH': [pH_input.value],\n",
        "        'Area_in_hectares': [area_input.value],\n",
        "        'rainfall': [rainfall_input.value],\n",
        "        'Production_in_tons': [production_input.value],\n",
        "        'State_Name': [state_input.value],  # Get selected state\n",
        "        'Crop_Type': [crop_type_input.value],  # Get selected crop type\n",
        "        'Crop': [crop_input.value]  # Get selected crop\n",
        "    })\n",
        "\n",
        "    # Encode categorical features\n",
        "    input_data['State_Name_Encoded'] = state_encoder.transform(input_data['State_Name'])\n",
        "    input_data['Crop_Type_Encoded'] = crop_type_encoder.transform(input_data['Crop_Type'])\n",
        "    input_data['Crop_Encoded'] = crop_encoder.transform(input_data['Crop'])\n",
        "\n",
        "    # Ensure the order of columns matches the training data\n",
        "    input_data = input_data[['N', 'P', 'K', 'pH', 'rainfall', 'temperature', 'Area_in_hectares', 'Production_in_tons',\n",
        "                            'State_Name_Encoded', 'Crop_Type_Encoded', 'Crop_Encoded']]  # Added encoded features\n",
        "\n",
        "    predictions = model.predict(input_data)\n",
        "    predicted_value = predictions[0]*907.185\n",
        "    print(\"Predicted Value in tons:\", predictions[0])\n",
        "\n",
        "\n",
        "# Create a button to trigger prediction\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "predict_button.on_click(predict_on_input)\n",
        "\n",
        "# Display the input widgets and button\n",
        "display(N_input, P_input, K_input, temperature_input, pH_input, area_input,\n",
        "        rainfall_input, production_input, state_input, crop_type_input, crop_input, predict_button)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Wf7CDJsAQPTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0Wpf4Nm1Ms9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}